{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CIFAR-10 model\n",
    "This is taken from https://github.com/ARM-software/CMSIS_5/tree/develop/CMSIS/NN/Examples/ARM/arm_nn_examples/cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab parameters\n",
    "These are in tensorflow-models/cmsis_pretrained/arm_nnexamples_cifar10_parameter.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV1_IM_DIM = 32\n",
    "CONV1_IM_CH = 3\n",
    "CONV1_KER_DIM = 5\n",
    "CONV1_PADDING = 2\n",
    "CONV1_STRIDE = 1\n",
    "CONV1_OUT_CH = 32\n",
    "CONV1_OUT_DIM = 32\n",
    "\n",
    "POOL1_KER_DIM = 3\n",
    "POOL1_STRIDE = 2\n",
    "POOL1_PADDING = 0\n",
    "POOL1_OUT_DIM = 16\n",
    "\n",
    "CONV2_IM_DIM = 16\n",
    "CONV2_IM_CH = 32\n",
    "CONV2_KER_DIM = 5\n",
    "CONV2_PADDING = 2\n",
    "CONV2_STRIDE = 1\n",
    "CONV2_OUT_CH = 16\n",
    "CONV2_OUT_DIM = 16\n",
    "\n",
    "POOL2_KER_DIM = 3\n",
    "POOL2_STRIDE = 2\n",
    "POOL2_PADDING = 0\n",
    "POOL2_OUT_DIM = 8\n",
    "\n",
    "CONV3_IM_DIM = 8\n",
    "CONV3_IM_CH = 16\n",
    "CONV3_KER_DIM = 5\n",
    "CONV3_PADDING = 2\n",
    "CONV3_STRIDE = 1\n",
    "CONV3_OUT_CH = 32\n",
    "CONV3_OUT_DIM = 8\n",
    "\n",
    "POOL3_KER_DIM = 3\n",
    "POOL3_STRIDE = 2\n",
    "POOL3_PADDING = 0\n",
    "POOL3_OUT_DIM = 4\n",
    "\n",
    "IP1_DIM = 4*4*32\n",
    "IP1_IM_DIM = 4\n",
    "IP1_IM_CH = 32\n",
    "IP1_OUT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pretrained_data(fName, pretrained_data):\n",
    "    with open(fName) as fp:\n",
    "        for line in fp:\n",
    "            if len(line) == 0 or line[0] != '#':\n",
    "                continue\n",
    "            line = line.split()\n",
    "            param = line[1]\n",
    "            data = line[2]\n",
    "            if '{' in data:\n",
    "                data = re.sub(\"[{}]\", \"\", data)\n",
    "                pretrained_data[param] = np.array(map(int, data.split(',')))\n",
    "            else:\n",
    "                pretrained_data[param] = int(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd = {}\n",
    "parse_pretrained_data(\"cmsis_pretrained/arm_nnexamples_cifar10_inputs.h\", ptd)\n",
    "parse_pretrained_data(\"cmsis_pretrained/arm_nnexamples_cifar10_weights.h\", ptd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ptd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to make this 4D\n",
    "ptd[\"IMG_DATA\"] = ptd[\"IMG_DATA\"].reshape((CONV1_IM_DIM, CONV1_IM_DIM, CONV1_IM_CH))\n",
    "#https://stackoverflow.com/questions/36223157/set-weight-and-bias-tensors-of-tensorflow-conv2d-operation\n",
    "ptd[\"CONV1_WT\"] = ptd[\"CONV1_WT\"].reshape((CONV1_KER_DIM, CONV1_KER_DIM, CONV1_IM_CH, CONV1_OUT_CH))\n",
    "ptd[\"CONV2_WT\"] = ptd[\"CONV2_WT\"].reshape((CONV2_KER_DIM, CONV2_KER_DIM, CONV1_OUT_CH, CONV2_OUT_CH))\n",
    "ptd[\"CONV3_WT\"] = ptd[\"CONV3_WT\"].reshape((CONV3_KER_DIM, CONV3_KER_DIM, CONV2_OUT_CH, CONV3_OUT_CH))\n",
    "ptd[\"IP1_WT\"] = ptd[\"IP1_WT\"].reshape((IP1_IM_DIM, IP1_IM_DIM, IP1_IM_CH, IP1_OUT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(input_image):\n",
    "  with tf.name_scope(\"Layer1\"):\n",
    "    CONV1_WT = weight_variable(ptd['CONV1_WT'], name='CONV1_WT')\n",
    "    b_fc1 = bias_variable(ptd['CONV1_BIAS'], name='CONV1_BIAS')\n",
    "    conv_kernel_1 = tf.nn.conv2d(input_image, CONV1_WT, [1, CONV1_STRIDE, CONV1_STRIDE, 1], padding='SAME')\n",
    "bias_layer_1 = tf.nn.bias_add(conv_kernel_1, biases_1_array)\n",
    "    a_fc1 = tf.add(tf.matmul(x, W_fc1), b_fc1, name=\"zscore\")\n",
    "    h_fc1 = tf.nn.relu(a_fc1)\n",
    "\n",
    "  with tf.name_scope(\"Layer2\"):\n",
    "    W_fc2 = weight_variable([128, 64], name='W_fc2')\n",
    "    b_fc2 = bias_variable([64], name='b_fc2')\n",
    "    a_fc2 = tf.add(tf.matmul(h_fc1, W_fc2), b_fc2, name=\"zscore\")\n",
    "    h_fc2 = tf.nn.relu(a_fc2)\n",
    "  \n",
    "  with tf.name_scope(\"OuputLayer\"):\n",
    "    W_fc3 = weight_variable([64, 10], name='W_fc3')\n",
    "    b_fc3 = bias_variable([10], name='b_fc3')\n",
    "    logits = tf.add(tf.matmul(h_fc2, W_fc3), b_fc3, name=\"logits\")\n",
    "    y_pred = tf.argmax(logits, 1, name='y_pred')\n",
    "\n",
    "  return y_pred, logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
